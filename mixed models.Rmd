---
title: "Linear Mixed Models"
author: "Andrew Stewart"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(lme4)
library(lmerTest)
library(emmeans)
```

## Linear Mixed Models
Today we are now going to turn to mixed models.  

#Q1
Within R, import the dataset "data1.csv".  These data are from a reaction time experiment.  Fifty participants had to respond to a word on the screen.  Their task was to press a button on a button box only when they recognized the word (our DV is measures in milliseconds).  The words were either Rare or Common.  The design is repeated measures.  We might expect Common words to be recognized more quickly than Common words.  Run the appropriate LMM to determine whether this is indeed correct.

```{r, message=FALSE}
data <- read_csv("data1.csv")
```

First we need to make sure that our Subject, Item, and Condition columns are all factors - the first two we will use as our random effects, the third as our fixed effect:

```{r}
data$Subject <- as.factor(data$Subject)
data$Item <- as.factor(data$Item)
data$Condition <- as.factor(data$Condition)
```

Let's build a plot:

```{r, warning=FALSE}
data %>%
  ggplot(aes(x = Condition, y = RT, colour = Condition)) +
  geom_violin() +
  geom_jitter(alpha = .2, width = .2) +
  guides(colour = FALSE) +
  geom_boxplot(width = .2, colour = "black", alpha = 0) +
  coord_flip()
```

Generate some descriptives:

```{r}
data %>% group_by(Condition) %>% 
  filter(!is.na(RT)) %>% 
  summarise(mean = mean(RT), sd = sd(RT))
```

Let's run a basic mixed model first:

```{r}
model1 <- lmer(RT ~ Condition + (1 + Condition | Subject) + (1 + Condition | Item), data = data, REML = TRUE )
summary(model1)
```

We can see we have an effect of condition - the Intercept corresponds to our 'Common' condition and our ConditionRare estimate corresponds to the difference between our 'Common' and 'Rare' conditions.  In other words, our 'Rare' condition words are about 200 msec. slower to respond to. That fits with the descriptives we calculated earlier.  The estimates differ slighly from our descriptives as we have a missing data point which we can see by using the filter() function to display cases where we have missing RT data (indicated by NA).

```{r}
filter(data, is.na(RT))
```

How do the residuals look?

```{r}
qqnorm(residuals(model1))
```

OK, so these don't look too normal.  We now have a couple of options - we could log transform our DV... 

```{r}
model2 <- lmer(log(RT) ~ Condition + (1 | Subject) + (1 | Item), data = data, REML = TRUE)
summary(model2)
```

The same finding holds - with the 'Rare' condition taking longer to read.  Interpreting the estimates is harder though as they are log transformed... Do the residuals now look normally distributed?

```{r}
qqnorm(residuals(model2))
```

This is looking better than modelling over the untransformed data. Another option would be to build a generalised linear mixed model assuming sampling from the Gamma distribution.


